# í”„ë¡œì íŠ¸ëª…

ğŸ“¢ 2025ë…„ 2í•™ê¸° [AIKU](https://github.com/AIKU-Official) í™œë™ìœ¼ë¡œ ì§„í–‰í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤

ğŸ‰ 2025ë…„ 2í•™ê¸° AIKU - ì—´ì‹¬íˆìƒ ìˆ˜ìƒ!

## ì†Œê°œ

ì˜í™”, ë“œë¼ë§ˆ, ë®¤ì§ë¹„ë””ì˜¤ ì œì‘ì„ ìœ„í•œ AI ê¸°ë°˜ ìŠ¤í† ë¦¬ë³´ë“œ ìŠ¤ì¼€ì¹˜ ìë™ ìƒì„± ì‹œìŠ¤í…œ

Scene ì •ë³´(ì¥ë©´ ì„¤ëª…, ëŒ€ì‚¬)ì™€ Shot ì •ë³´(Close-up shot, Medium shot, Full shot)ë¥¼ ì…ë ¥ë°›ì•„ ê¹¨ë—í•œ ìŠ¤ì¼€ì¹˜ í˜•íƒœì˜ ìŠ¤í† ë¦¬ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ì˜€ìŠµë‹ˆë‹¤. 

## ë°©ë²•ë¡ 
**[ëª¨ë¸ë§ ì „ëµ] Textual Embedding ê¸°ë°˜ì˜ ì •êµí•œ ìƒ·(Shot) ì œì–´**

- **Base Model & Fine-tuning Strategy**
    - **Backbone:** Stable Diffusion v1.5
    - **Optimization:** LoRA (Low-Rank Adaptation)ë¥¼ ì ìš©í•˜ì—¬ ì ì€ ì—°ì‚°ëŸ‰ìœ¼ë¡œ ëª©í‘œ ìŠ¤í† ë¦¬ë³´ë“œ ì‘í™” ìŠ¤íƒ€ì¼ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµ.

**Model Architecture**

<img width="1280" height="720" alt="pipeline" src="https://github.com/user-attachments/assets/54334050-e7e1-4f64-8c91-e3844c6a9b2e" />


- **í•µì‹¬ ë°©ë²•ë¡ : Textual Embedding**

íŠ¹íˆ ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì›í•˜ëŠ” êµ¬ë„ë¥¼ ì •í™•í•˜ê²Œ ìƒì„±í•´ë‚´ê¸° ìœ„í•´ **Textual Embedding** ê¸°ë²•ì„ ì¤‘ì ì ìœ¼ë¡œ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ ê¸°ë²•ì€ ê¸°ì¡´ DreamBooth ì—°êµ¬ ë“±ì—ì„œ ì œì•ˆëœ 'í¬ê·€ í† í°(Rare Token)ì„ í™œìš©í•œ ì£¼ì²´(Subject) í•™ìŠµ' ë°©ì‹ì„ ì‘ìš©í•œ ê²ƒì…ë‹ˆë‹¤.

ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œëŠ” 'í´ë¡œì¦ˆì—…', 'í’€ìƒ·' ë“±ì˜ ì¹´ë©”ë¼ ì›Œí‚¹ì„ ì¼ê´€ì„± ìˆê²Œ ì œì–´í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” **CLIP Text Encoderì˜ ì„ë² ë”© ë ˆì´ì–´**ì— ìƒ·(Shot) ì •ë³´ë¥¼ ë‹´ì€ ìƒˆë¡œìš´ í† í°ì„ ì¶”ê°€í•˜ì—¬ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤.

- **Custom Tokens:**
    - `<cu_trg>`: ì–¼êµ´ í‘œì •ê³¼ ê°ì •ì„ ê°•ì¡°í•˜ëŠ” **Close Up** ì •ë³´ í•™ìŠµ
    - `<ms_trg>`: ì¸ë¬¼ì˜ ë™ì‘ê³¼ ìƒë°˜ì‹ ì„ í‘œí˜„í•˜ëŠ” **Medium Shot** ì •ë³´ í•™ìŠµ
    - `<fs_trg>`: ì¸ë¬¼ì˜ ì „ì‹ ê³¼ ê³µê°„ê°ì„ ë‚˜íƒ€ë‚´ëŠ” **Full Shot** ì •ë³´ í•™ìŠµ

ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ì‚¬ìš©ìê°€ ì…ë ¥í•œ í† í°ì— ë§ì¶° í™”í’(Style)ì€ ìœ ì§€í•˜ë˜, ìŠ¤í† ë¦¬ë³´ë“œ ì—°ì¶œì— í•„ìˆ˜ì ì¸ **êµ¬ë„(Composition) ì •ë³´**ë¥¼ ëª…í™•í•˜ê²Œ ë¶„ë¦¬í•˜ì—¬ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

> ReferenceRuiz, N., et al. "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation." CVPR 2023.
>
## í™˜ê²½ ì„¤ì •

í”„ë¡œì íŠ¸ ì‹¤í–‰ì„ ìœ„í•´ ì•„ë˜ì˜ ìš”êµ¬ ì‚¬ì–‘ ë° ì„¤ì¹˜ ë‹¨ê³„ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.

### 1. ìš”êµ¬ ì‚¬í•­ (Prerequisites)

* **OS**: Linux (Ubuntu ê¶Œì¥)
* **GPU**: NVIDIA GPU (CUDA 11.8 í˜¸í™˜, ìµœì†Œ VRAM 24GB ê¶Œì¥)
* **Python**: v3.11
* **Conda**: Anaconda ë˜ëŠ” Miniconda ì‚¬ìš© ê¶Œì¥

### 2. ì„¤ì¹˜ ë‹¨ê³„ (Installation)

**Step 1: Conda ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”**

```bash
conda create -n storyboard python=3.11 -y
conda activate storyboard

```

**Step 2: PyTorch ë° CUDA íˆ´í‚· ì„¤ì¹˜**

```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

```

**Step 3: í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜**

```bash
pip install -r requirements.txt

```

**Step 4: Accelerate í™˜ê²½ ì„¤ì • (ë©€í‹° GPU ì‚¬ìš© ì‹œ)**

```bash
accelerate config

```

---

## ì‚¬ìš© ë°©ë²•

### 1. ë°ì´í„° ì „ì²˜ë¦¬ (Data Preprocessing)

í•™ìŠµ ì „, `Data_preprocessing_method/` í´ë” ë‚´ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.

* **ë°ì´í„° ì¶”ì¶œ**: `python 00_extract_dataset.py`
* **íƒœê·¸ ì „ì²˜ë¦¬**: `python 01_preprocess_tags.py`

### 2. ëª¨ë¸ í•™ìŠµ (Training)

ì œê³µëœ `train.sh` ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. `accelerate`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©€í‹° GPU í™˜ê²½ì—ì„œ ìµœì í™”ëœ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
bash train.sh

# ì§ì ‘ ì‹¤í–‰ ì‹œ ì˜ˆì‹œ
python train.py \
  --pretrained_model_name_or_path "/path/to/model" \
  --train_data_dir "/path/to/Dataset" \
  --resolution 512 \
  --train_batch_size 6 \
  --num_train_epochs 25 \
  --mixed_precision "fp16" \
  --output_dir "./output"

```

### 3. ì¶”ë¡  (Inference)

í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
bash inference.sh

# ì§ì ‘ ì‹¤í–‰ ì‹œ ì˜ˆì‹œ
python inference.py \
  --base-model "/path/to/base_model" \
  --checkpoint "/path/to/checkpoint" \
  --trigger-word "<ms_trg>" \
  --prompt "medium shot, Eye level, a character standing in the forest" \
  --fuse-lora \
  --output "result.png"

```

### 4. ê²€ì¦ ë° ë°°ì¹˜ ìƒì„± (Validation)

* ë°°ì¹˜ ê²°ê³¼ ìƒì„±: `python batch_generate.py`
* ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸: `bash validation.sh`


## ì˜ˆì‹œ ê²°ê³¼
**Input text = " Eye level, female, youth, happy, slim body, white shirt, black pants, no background, day time "**

<img width="1769" height="593" alt="image" src="https://github.com/user-attachments/assets/29988724-fc99-440b-b878-6677a67d3144" />

ë™ì¼ Promptì— ëŒ€í•´ Shot ë³„ë¡œ Trigger Wordë¥¼ ì„¤ì •í•˜ì—¬ Inferenceí•œ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤.
Textë¥¼ ì˜ ë°˜ì˜í•œ Consistentí•œ ê·¸ë¦¼ì²´ë¡œ, Shot ë³„ ì°¨ì´ê°€ í™•ì—°íˆ ë“œëŸ¬ë‚˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

## íŒ€ì›

- [ì‹ ëª…ê²½] : Lead, Model Architecture, Data Augmentation
- [ê¹€íƒœê´€] : Experiment, Pipeline Construction, Data Clustering
- [ì •ì„±ìœ¤] : Image Preprocessing
- [ë°•ì„œì—°] : Text Data Preprocessing
- [ì¥ì„œí˜„] : Data Preprocessing, Evaluation Metrics

